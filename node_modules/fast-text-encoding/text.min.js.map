{
  "version": 3,
  "sources": ["src/buffer.js", "src/lowlevel.js", "src/shared.js", "src/support.js", "src/o-encoder.js", "src/xhr.js", "src/o-decoder.js", "src/polyfill.js"],
  "sourcesContent": ["\n/**\n * @param {Uint8Array} bytes\n * @param {string} encoding\n * @return {string}\n */\nexport function decodeBuffer(bytes, encoding) {\n  /** @type {Buffer} */\n  var b;\n  if (bytes instanceof Buffer) {\n    // @ts-ignore\n    b = bytes;\n  } else {\n    b = Buffer.from(bytes.buffer, bytes.byteOffset, bytes.byteLength);\n  }\n  return b.toString(/** @type {BufferEncoding} */(encoding));\n}\n\n\n/**\n * @param {string} string\n * @return {Uint8Array}\n */\nexport var encodeBuffer = (string) => Buffer.from(string);\n", "\n/**\n * @param {Uint8Array} bytes\n * @return {string}\n */\nexport function decodeFallback(bytes) {\n  var inputIndex = 0;\n\n  // Create a working buffer for UTF-16 code points, but don't generate one\n  // which is too large for small input sizes. UTF-8 to UCS-16 conversion is\n  // going to be at most 1:1, if all code points are ASCII. The other extreme\n  // is 4-byte UTF-8, which results in two UCS-16 points, but this is still 50%\n  // fewer entries in the output.\n  var pendingSize = Math.min(256 * 256, bytes.length + 1);\n  var pending = new Uint16Array(pendingSize);\n  var chunks = [];\n  var pendingIndex = 0;\n\n  for (; ;) {\n    var more = inputIndex < bytes.length;\n\n    // If there's no more data or there'd be no room for two UTF-16 values,\n    // create a chunk. This isn't done at the end by simply slicing the data\n    // into equal sized chunks as we might hit a surrogate pair.\n    if (!more || (pendingIndex >= pendingSize - 1)) {\n      // nb. .apply and friends are *really slow*. Low-hanging fruit is to