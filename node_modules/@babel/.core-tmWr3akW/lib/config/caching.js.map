{"version":3,"names":["_gensync","data","require","_async","_util","synchronize","gen","gensync","sync","genTrue","makeWeakCache","handler","makeCachedFunction","WeakMap","makeWeakCacheSync","makeStrongCache","Map","makeStrongCacheSync","CallCache","callCacheSync","callCacheAsync","futureCache","cachedFunction","arg","asyncContext","isAsync","callCache","cached","getCachedValueOrWait","valid","value","cache","CacheConfigurator","handlerResult","finishLock","isIterableIterator","onFirstPause","setupAsyncLocks","updateFunctionCache","delete","release","getCachedValue","cachedValue","get","waitFor","promise","config","Lock","configured","forever","deactivate","mode","set","validator","push","constructor","_active","_never","_forever","_invalidate","_configured","_pairs","_data","simple","makeSimpleConfigurator","Error","never","using","key","fn","maybeAsync","isThenable","then","invalidate","pairs","cacheFn","val","assertSimpleType","cb","released","_resolve","Promise","resolve"],"sources":["../../src/config/caching.ts"],"sourcesContent":["import gensync from \"gensync\";\nimport type { Handler } from \"gensync\";\nimport {\n  maybeAsync,\n  isAsync,\n  onFirstPause,\n  waitFor,\n  isThenable,\n} from \"../gensync-utils/async.ts\";\nimport { isIterableIterator } from \"./util.ts\";\n\nexport type { CacheConfigurator };\n\nexport type SimpleCacheConfigurator = {\n  (forever: boolean): void;\n  <T>(handler: () => T): T;\n\n  forever: () => void;\n  never: () => void;\n  using: <T>(handler: () => T) => T;\n  invalidate: <T>(handler: () => T) => T;\n};\n\nexport type CacheEntry<ResultT, SideChannel> = Array<{\n  value: ResultT;\n  valid: (channel: SideChannel) => Handler<boolean>;\n}>;\n\nconst synchronize = <ArgsT extends unknown[], ResultT>(\n  gen: (...args: ArgsT) => Handler<ResultT>,\n): ((...args: ArgsT) => ResultT) => {\n  return gensync(gen).sync;\n};\n\n// eslint-disable-next-line require-yield\nfunction* genTrue() {\n  return true;\n}\n\nexport function makeWeakCache<ArgT extends object, ResultT, SideChannel>(\n  handler: (\n    arg: ArgT,\n    cache: CacheConfigurator<SideChannel>,\n  ) => Handler<ResultT> | ResultT,\n): (arg: ArgT, data: SideChannel) => Handler<ResultT> {\n  return makeCachedFunction<ArgT, ResultT, SideChannel>(WeakMap, handler);\n}\n\nexport function makeWeakCacheSync<ArgT extends object, ResultT, SideChannel>(\n  handler: (arg: ArgT, cache?: CacheConfigurator<SideChannel>) => ResultT,\n): (arg: ArgT, data?: SideChannel) => ResultT {\n  return synchronize<[ArgT, SideChannel], ResultT>(\n    makeWeakCache<ArgT, ResultT, SideChannel>(handler),\n  );\n}\n\nexport function makeStrongCache<ArgT, ResultT, SideChannel>(\n  handler: (\n    arg: ArgT,\n    cache: CacheConfigurator<SideChannel>,\n  ) => Handler<ResultT> | ResultT,\n): (arg: ArgT, data: SideChannel) => Handler<ResultT> {\n  return makeCachedFunction<ArgT, ResultT, SideChannel>(Map, handler);\n}\n\nexport function makeStrongCacheSync<ArgT, ResultT, SideChannel>(\n  handler: (arg: ArgT, cache?: CacheConfigurator<SideChannel>) => ResultT,\n): (arg: ArgT, data?: SideChannel) => ResultT {\n  return synchronize<[ArgT, SideChannel], ResultT>(\n    makeStrongCache<ArgT, ResultT, SideChannel>(handler),\n  );\n}\n\n/* NOTE: Part of the logic explained in this comment is explained in the\n *       getCachedValueOrWait and setupAsyncLocks functions.\n *\n * > There are only two hard things in Computer Science: cache invalidation and naming things.\n * > -- Phil Karlton\n *\n * I don't know if Phil was also thinking about handling a cache whose invalidation function is\n * defined asynchronously is considered, but it is REALLY hard to do correctly.\n *\n * The implemented logic (only when gensync is run asynchronously) is the following:\n *   1. If there is a valid cache associated to the current \"arg\" parameter,\n *       a. RETURN the cached value\n *   3. If there is a FinishLock associated to the current \"arg\" parameter representing a valid cache,\n *       a. Wait for that lock to be released\n *       b. RETURN the value associated with that lock\n *   5. Start executing the function to be cached\n *       a. If it pauses on a promise, then\n *           i. Let FinishLock be a new lock\n *          ii. Store FinishLock as associated to the current \"arg\" parameter\n *         iii. Wait for the function to finish executing\n *          iv. Release FinishLock\n *           v. Send the function result to anyone waiting on FinishLock\n *   6. Store the result in the cache\n *   7. RETURN the result\n */\nfunction makeCachedFunction<ArgT, ResultT, SideChannel>(\n  CallCache: new <Cached>() => CacheMap<ArgT, Cached, SideChannel>,\n  handler: (\n    arg: ArgT,\n    cache: CacheConfigurator<SideChannel>,\n  ) => Handler<ResultT> | ResultT,\n): (arg: ArgT, data: SideChannel) => Handler<ResultT> {\n  const callCacheSync = new CallCache<ResultT>();\n  const callCacheAsync = new CallCache<ResultT>();\n  const futureCache = new CallCache<Lock<ResultT>>();\n\n  return function* cachedFunction(arg: ArgT, data: SideChannel) {\n    const asyncContext = yield* isAsync();\n    const callCache = asyncContext ? callCacheAsync : callCacheSync;\n\n    const cached = yield* getCachedValueOrWait<ArgT, ResultT, SideChannel>(\n      asyncContext,\n      callCache,\n      futureCache,\n      arg,\n      data,\n    );\n    if (cached.valid) return cached.value;\n\n    const cache = new CacheConfigurator(data);\n\n    const handlerResult: Handler<ResultT> | ResultT = handler(arg, cache);\n\n    let finishLock: Lock<ResultT>;\n    let value: ResultT;\n\n    if (isIterableIterator(handlerResult)) {\n      value = yield* onFirstPause(handlerResult, () => {\n        finishLock = setupAsyncLocks(cache, futureCache, arg);\n      });\n    } else {\n      value = handlerResult;\n    }\n\n    updateFunctionCache(callCache, cache, arg, value);\n\n    if (finishLock) {\n      futureCache.delete(arg);\n      finishLock.release(value);\n    }\n\n    return value;\n  };\n}\n\ntype CacheMap<ArgT, ResultT, SideChannel> =\n  | Map<ArgT, CacheEntry<ResultT, SideChannel>>